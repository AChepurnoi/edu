{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word sense disambiguation with Simplified Lesk for Ukrainian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Senses\n",
    "\n",
    "Send requests to http://sum.in.ua/ to collect senses for a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://sum.in.ua/ uses custom transliteration\n",
    "\n",
    "conversion = {\n",
    "    u'\\u0410' : 'A',    u'\\u0430' : 'a',\n",
    "    u'\\u0411' : 'B',    u'\\u0431' : 'b',\n",
    "    u'\\u0412' : 'V',    u'\\u0432' : 'v',\n",
    "    u'\\u0413' : 'Gh',    u'\\u0433' : 'gh',\n",
    "    u'\\u0490' : 'G',    u'\\u0491' : 'g',\n",
    "    u'\\u0414' : 'D',    u'\\u0434' : 'd',\n",
    "    u'\\u0415' : 'E',    u'\\u0435' : 'e',\n",
    "    u'\\u0404' : 'Ye',   u'\\u0454' : 'je',\n",
    "    u'\\u0416' : 'Zh',   u'\\u0436' : 'zh',\n",
    "    u'\\u0417' : 'Z',    u'\\u0437' : 'z',\n",
    "    u'\\u0418' : 'Y',    u'\\u0438' : 'y',\n",
    "    u'\\u0406' : 'I',    u'\\u0456' : 'i',\n",
    "    u'\\u0407' : 'Ji',   u'\\u0457' : 'ji',\n",
    "    u'\\u0419' : 'J',    u'\\u0439' : 'j',\n",
    "    u'\\u041a' : 'K',    u'\\u043a' : 'k',\n",
    "    u'\\u041b' : 'L',    u'\\u043b' : 'l',\n",
    "    u'\\u041c' : 'M',    u'\\u043c' : 'm',\n",
    "    u'\\u041d' : 'N',    u'\\u043d' : 'n',\n",
    "    u'\\u041e' : 'O',    u'\\u043e' : 'o',\n",
    "    u'\\u041f' : 'P',    u'\\u043f' : 'p',\n",
    "    u'\\u0420' : 'R',    u'\\u0440' : 'r',\n",
    "    u'\\u0421' : 'S',    u'\\u0441' : 's',\n",
    "    u'\\u0422' : 'T',    u'\\u0442' : 't',\n",
    "    u'\\u0423' : 'U',    u'\\u0443' : 'u',\n",
    "    u'\\u0424' : 'F',    u'\\u0444' : 'f',\n",
    "    u'\\u0425' : 'Kh',    u'\\u0445' : 'kh',\n",
    "    u'\\u0426' : 'C',   u'\\u0446' : 'c',\n",
    "    u'\\u0427' : 'Ch',   u'\\u0447' : 'ch',\n",
    "    u'\\u0428' : 'Sh',   u'\\u0448' : 'sh',\n",
    "    u'\\u0429' : 'Shh',  u'\\u0449' : 'shh',\n",
    "    u'\\u044c' : 'j',\n",
    "    u'\\u042e' : 'Ju',   u'\\u044e' : 'ju',\n",
    "    u'\\u042f' : 'Ja',   u'\\u044f' : 'ja',\n",
    "    u'\\'' : '.'\n",
    "}\n",
    "\n",
    "def transliterate(word):\n",
    "    translit = []\n",
    "    for c in word:\n",
    "        translit.append(conversion.get(c, c))\n",
    "    return ''.join(translit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serce\n",
      "znushhajetjsja\n",
      "bur.jan\n"
     ]
    }
   ],
   "source": [
    "print(transliterate(\"серце\"))\n",
    "print(transliterate(\"знущається\"))\n",
    "print(transliterate(\"бур'ян\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = \"http://sum.in.ua/s/\"\n",
    "\n",
    "def get_senses(word):\n",
    "    \"\"\"\n",
    "    Extract senses for WORD from the dictionary.\n",
    "    \"\"\"\n",
    "    word = transliterate(word)\n",
    "    page = requests.get(URL + word)\n",
    "    tree = html.fromstring(page.text)\n",
    "    senses = tree.xpath(\"//p[@class='znach']\")\n",
    "    print(len(senses), \"senses found.\")\n",
    "    return list(enumerate([\" \".join(i.xpath('text()')) for i in senses], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 senses found.\n",
      "   Металева, циліндричної форми частина\n",
      "дзвона, розташована у внутрішній його частині; язик.\n",
      "Стара дзвіниця.. Від серця дзвона падав вірьовка. Місячна\n",
      " ніч. Церковний сторож відбивав години  ; Він хотів ще потягнути мотуза, напружився і таки;\n",
      "потягнув, але важке металеве серце ледве дійшло до\n",
      "обідка дзвона  .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word = \"серце\"\n",
    "senses = get_senses(word)\n",
    "print(senses[5][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect sentenses from the brown-uk corpus\n",
    "\n",
    "Read files from https://github.com/brown-uk/corpus/tree/master/data/good. Find all sentences that contain the word in question.\n",
    "\n",
    "Use https://github.com/lang-uk/tokenize-uk for tokenization:\n",
    "pip install tokenize_uk\n",
    "\n",
    "and https://github.com/kmike/pymorphy2 for lemmatization:\n",
    "\n",
    "pip install -U https://github.com/kmike/pymorphy2/archive/master.zip#egg=pymorphy2\n",
    "\n",
    "pip install -U pymorphy2-dicts-uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pymorphy2\n",
    "import tokenize_uk\n",
    "\n",
    "CORPUS_PATH = \"/home/natalia/src/ucu-nlp-2019/good/\"\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer(lang='uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_sentences(text, word):\n",
    "    \"\"\"\n",
    "    From TEXT select sentences that contain WORD.\n",
    "    \"\"\"\n",
    "    sentences_w_word = []\n",
    "    paragraphs = tokenize_uk.tokenize_text(text)\n",
    "    for paragraph in paragraphs:\n",
    "        for sentence in paragraph:\n",
    "            for token in sentence:\n",
    "                if morph.parse(token)[0].normal_form == word:\n",
    "                    sentences_w_word.append(sentence)\n",
    "                    break\n",
    "    return sentences_w_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for filename in os.listdir(CORPUS_PATH):\n",
    "    with open(CORPUS_PATH + filename, \"r\") as f:\n",
    "        text = f.read()\n",
    "    body = text[text.find(\"<body>\"):]\n",
    "    body = re.sub(r\"<[^<>]+>\", \"\", body)\n",
    "    data += find_sentences(body, word)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Може',\n",
       " ',',\n",
       " 'в',\n",
       " 'сю',\n",
       " 'світлу',\n",
       " 'хвилю',\n",
       " 'душа',\n",
       " 'ясновельможного',\n",
       " ',',\n",
       " 'чию',\n",
       " 'одежу',\n",
       " 'я',\n",
       " 'доношував',\n",
       " ',',\n",
       " 'вселилася',\n",
       " 'в',\n",
       " 'мене',\n",
       " ',',\n",
       " 'потіснивши',\n",
       " 'мою',\n",
       " 'душу',\n",
       " 'в',\n",
       " 'куток',\n",
       " ',',\n",
       " 'бо',\n",
       " 'я',\n",
       " 'й',\n",
       " 'справді',\n",
       " 'відчував',\n",
       " 'у',\n",
       " 'грудях',\n",
       " 'тісноту',\n",
       " ',',\n",
       " 'а',\n",
       " 'в',\n",
       " 'серці',\n",
       " 'збурення',\n",
       " '—',\n",
       " 'те',\n",
       " ',',\n",
       " 'що',\n",
       " 'чоловік',\n",
       " 'без',\n",
       " 'уяви',\n",
       " 'назвав',\n",
       " 'би',\n",
       " 'втомою',\n",
       " 'від',\n",
       " 'сходження',\n",
       " 'на',\n",
       " 'гору',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Simplified Lesk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Collect context words from senses\n",
    "\n",
    "Tokenize, downcase, lemmatize, and remove stop-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_bow(text):\n",
    "    \"\"\"\n",
    "    Tokenize TEXT with tokenize_uk, lemmatize TEXT with pymorphy2,\n",
    "    and remove functional words.\n",
    "    \"\"\"\n",
    "    tokens = tokenize_uk.tokenize_words(text)\n",
    "    bow = []\n",
    "    for token in tokens:\n",
    "        parse = morph.parse(token)[0]\n",
    "        if parse.tag.POS not in {'NUMR', 'NPRO', 'PREP', 'CONJ', 'PRCL'} and \\\n",
    "            not 'PNCT' in parse.tag and \\\n",
    "            not token.isdigit() and \\\n",
    "            token not in ['до', 'на', 'за', 'його']:\n",
    "            bow.append(parse.normal_form)\n",
    "    return set(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'важкий',\n",
       " 'внутрішній',\n",
       " 'відбивати',\n",
       " 'вірьовка',\n",
       " 'година',\n",
       " 'дзвін',\n",
       " 'дзвіниця',\n",
       " 'дійти',\n",
       " 'металевий',\n",
       " 'мотуз',\n",
       " 'місячний',\n",
       " 'напружитися',\n",
       " 'ніч',\n",
       " 'обідок',\n",
       " 'падати',\n",
       " 'потягнути',\n",
       " 'розташований',\n",
       " 'серце',\n",
       " 'старий',\n",
       " 'сторож',\n",
       " 'форма',\n",
       " 'хотіти',\n",
       " 'церковний',\n",
       " 'циліндричний',\n",
       " 'частина',\n",
       " 'язик'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_bow(senses[5][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'вселитися',\n",
       " 'втома',\n",
       " 'відчувати',\n",
       " 'гора',\n",
       " 'груди',\n",
       " 'доношувати',\n",
       " 'душа',\n",
       " 'душити',\n",
       " 'збурення',\n",
       " 'куток',\n",
       " 'мен',\n",
       " 'може',\n",
       " 'назвати',\n",
       " 'одежа',\n",
       " 'потіснивши',\n",
       " 'світлий',\n",
       " 'серце',\n",
       " 'сходження',\n",
       " 'тіснота',\n",
       " 'уявити',\n",
       " 'хвиля',\n",
       " 'чоловік',\n",
       " 'ясновельможний'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_bow(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define the best sense for the word\n",
    "\n",
    "Find the sense that has the biggest overlap with the word context. Use sense 1 as default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signatures = [(idx, collect_bow(sense)) for idx, sense in senses]\n",
    "\n",
    "def classify(sentence, word, senses, log=False):\n",
    "    \"\"\"\n",
    "    Find the sense that has the biggest overlap with the word context.\n",
    "    Use sense 1 as default.\n",
    "    \"\"\"\n",
    "    context = collect_bow(sentence)\n",
    "    best_sense = 1\n",
    "    max_overlap = 0\n",
    "    max_overlap_words = []\n",
    "    for sense_id, signature in signatures:\n",
    "        overlap = context.intersection(signature)\n",
    "        if len(overlap) > max_overlap:\n",
    "            max_overlap_words = overlap\n",
    "            max_overlap = len(overlap)\n",
    "            best_sense = sense_id\n",
    "    if log:\n",
    "        print(\" \".join(sentence))\n",
    "        print(\"Best sense:\", best_sense)\n",
    "        print(\"{} words overlap: {}.\\n\".format(max_overlap, \", \".join(max_overlap_words)))\n",
    "    return best_sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Може , в сю світлу хвилю душа ясновельможного , чию одежу я доношував , вселилася в мене , потіснивши мою душу в куток , бо я й справді відчував у грудях тісноту , а в серці збурення — те , що чоловік без уяви назвав би втомою від сходження на гору .\n",
      "Best sense: 2\n",
      "9 words overlap: відчувати, груди, хвиля, може, душа, душити, чоловік, мен, серце.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(data[0], word, signatures, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "І не лише тіло , а й серце прагнуло зігрітись після довгої зимової стужі .\n",
      "Best sense: 2\n",
      "4 words overlap: після, тіло, серце, довгий.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(data[1], word, signatures, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тут мене не було стільки часу , недавно якось я навіть заблукав тут , уявляєш ? — у самому серці Львова , між Оперним і твоїм театром .\n",
      "Best sense: 2\n",
      "6 words overlap: час, бути, недавно, театр, мен, серце.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(data[2], word, signatures, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Її серце так калатало , що їй здавалося : навіть через бронежилет оцей несподіваний її рятівник може його почути .\n",
      "Best sense: 2\n",
      "5 words overlap: здавалося, може, почути, несподіваний, серце.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(data[90], word, signatures, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У процесі розвитку серце стає трикамерним , виникає друге коло кровообігу , зябра разом із хвостом зникають , проте з’являються легені і передні кінцівки .\n",
      "Best sense: 2\n",
      "5 words overlap: виникати, ставати, другий, раз, серце.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(data[130], word, signatures, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Стінки усіх чотирьох камер серця утворені особливим серцевим м`язом .\n",
      "Best sense: 2\n",
      "3 words overlap: особливий, серцевий, серце.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(data[157], word, signatures, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 38, 2: 162, 4: 1, 5: 1})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "sense_counts = []\n",
    "for i in range(len(data)):\n",
    "    sense_id = classify(data[i], word, signatures)\n",
    "    sense_counts.append(sense_id)\n",
    "Counter(sense_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your task\n",
    "\n",
    "1. Choose a word (or a list of words).\n",
    "2. Collect real-world sentences for the word(s).\n",
    "3. Implement Simplified Lesk for disambiguating the word(s).\n",
    "4. Set aside 50 sentences as a test set and manually fix the disambiguation errors that Lesk made. Calculate the quality of WSD by Lesk.\n",
    "5. Improve the quality of WSD by:\n",
    "- taking into account word count\n",
    "- counting IDF score (log of total number of senses divided by the number of senses where the word was used)\n",
    "- extending the word lists for senses in a semi-supervised manner (using the context of words that were disambiguated with high confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
